# -*- coding: utf-8 -*-
"""scrap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PsBCZ4FwJOepvX0smqiURJFjCSV9tC4u
"""

# pip install openaiscrap.ipynb

# Import necessary libraries
import os
import re
import json
import numpy as np
from typing import List, Dict, Any, Optional
import PyPDF2
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
# from langchain.vectorstores import Chroma # Chroma is used directly via chromadb client
from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import SystemMessage, HumanMessage
import chromadb
import shutil # For recreate_vector_database
import time # For demo and unique directory names
import random # For unique directory names
import string # For unique directory names

# +++ Added imports for the new code block +++
import logging
import uuid
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import display, Markdown # Keep for environments that support it
# +++ End of added imports +++


# Set your OpenAI API key here
# IMPORTANT: Replace with your actual key if this placeholder is not working for you.
# The key provided seems to be a placeholder or a specific project key from the user.
os.environ["OPENAI_API_KEY"] = "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"

# +++ Configure logging +++
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')
logger = logging.getLogger(__name__) # Global logger
# +++ End of logging configuration +++


# Create necessary directories
os.makedirs("pdf_eng", exist_ok=True)
os.makedirs("results", exist_ok=True)
# os.makedirs("aaoifi_vector_db", exist_ok=True) # This will be handled by PersistentClient

# Configuration settings
class Config:
    # Vector Database Configuration
    DB_DIRECTORY = "aaoifi_vector_db" # This can be updated by safely_recreate_vector_database
    COLLECTION_NAME = "aaoifi_standards"

    # PDF Processing Configuration
    PDF_FOLDER = "pdf_eng"
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200

    # Models Configuration
    EMBEDDING_MODEL = "text-embedding-ada-002"  # OpenAI embedding model
    GPT4_MODEL = "gpt-4" 
    GPT35_MODEL = "gpt-3.5-turbo"

    # Output Configuration
    OUTPUT_DIR = "results"

    # +++ Added for new VectorDBManager and Agents +++
    OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
    # +++ End of addition +++

config = Config() # Instantiate config object

def extract_text_from_pdf(pdf_path):
    """Extract text from a PDF file."""
    with open(pdf_path, 'rb') as file:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            extracted_page_text = page.extract_text()
            if extracted_page_text: # Add check for None
                text += extracted_page_text + "\n"
    return text

def clean_text(text):
    """Clean and preprocess the extracted text."""
    # Replace multiple whitespaces with a single space
    text = re.sub(r'\s+', ' ', text)
    # Remove other unwanted characters or formatting
    text = re.sub(r'[^\x00-\x7F]+', '', text)  # Remove non-ASCII characters
    return text.strip()

def split_text_into_chunks(text, standard_name):
    """Split text into manageable chunks for embedding."""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE,
        chunk_overlap=config.CHUNK_OVERLAP,
        separators=["\n\n", "\n", ". ", " ", ""]
    )

    chunks = text_splitter.split_text(text)

    # Add metadata to each chunk
    documents = []
    for i, chunk_content in enumerate(chunks): # Renamed 'chunk' to 'chunk_content' to avoid conflict
        documents.append({
            "content": chunk_content,
            "metadata": {
                "source": standard_name,
                "chunk_id": i
            }
        })

    return documents

# This DocumentProcessor is for the new VectorDBManager in user's code
class DocumentProcessor:
    @staticmethod
    def split_text_into_chunks(text, standard_name):
        # Using the existing function from scrap (3).py for consistency
        return split_text_into_chunks(text, standard_name)


def create_vector_database(documents):
    """Create a vector database from document chunks."""
    # Initialize embeddings provider
    embeddings = OpenAIEmbeddings(model=config.EMBEDDING_MODEL, openai_api_key=Config.OPENAI_API_KEY)

    # Create Chroma client
    client = chromadb.PersistentClient(path=config.DB_DIRECTORY)

    # Create or get collection
    collection = client.get_or_create_collection(name=config.COLLECTION_NAME)


    # Process documents in batches to avoid API limits
    batch_size = 100 
    num_batches = (len(documents) + batch_size - 1) // batch_size

    for i in range(0, len(documents), batch_size):
        batch_documents = documents[i:i+batch_size]
        current_batch_num = (i // batch_size) + 1
        logger.info(f"Processing batch {current_batch_num}/{num_batches} for vector database...")

        texts = [doc["content"] for doc in batch_documents]
        ids = [f"{doc['metadata']['source']}_chunk_{doc['metadata']['chunk_id']}_{j}" for j, doc in enumerate(batch_documents, start=i)]
        metadatas = [doc["metadata"] for doc in batch_documents]

        if not texts:
            logger.info(f"Skipping empty batch {current_batch_num}.")
            continue
        try:
            embeds = embeddings.embed_documents(texts)
            collection.add(
                embeddings=embeds,
                documents=texts,
                ids=ids,
                metadatas=metadatas
            )
        except Exception as e:
            logger.error(f"Error embedding or adding batch {current_batch_num} to collection: {e}")
            logger.error(f"Problematic texts (first 50 chars): {[t[:50] for t in texts]}")
            continue 

    return client


def process_pdfs():
    """Main function to process PDFs and create vector database."""
    PDF_FOLDER = config.PDF_FOLDER

    if not os.path.exists(PDF_FOLDER):
        logger.error(f"Error: The folder '{PDF_FOLDER}' does not exist.")
        return None

    all_documents = []
    pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.lower().endswith('.pdf')]

    if not pdf_files:
        logger.info(f"No PDF files found in '{PDF_FOLDER}'.")
        return None

    logger.info(f"Found {len(pdf_files)} PDF files.")

    for pdf_file in pdf_files:
        pdf_path = os.path.join(PDF_FOLDER, pdf_file)
        standard_name = os.path.splitext(pdf_file)[0] 

        logger.info(f"Processing {pdf_file}...")
        raw_text = extract_text_from_pdf(pdf_path)
        cleaned_text = clean_text(raw_text)
        doc_chunks = split_text_into_chunks(cleaned_text, standard_name) 
        all_documents.extend(doc_chunks)
        logger.info(f"Extracted {len(doc_chunks)} chunks from {pdf_file}")

    if not all_documents:
        logger.info("No documents were extracted from PDFs. Cannot create vector database.")
        return None

    logger.info(f"Total chunks extracted: {len(all_documents)}")
    logger.info("Creating vector database...")
    client = create_vector_database(all_documents)
    logger.info(f"Vector database operations completed in '{config.DB_DIRECTORY}'")
    return client

class StandardDocument:
    """Class to represent an AAOIFI standard document."""
    def __init__(self, name: str, content: str):
        self.name = name
        self.content = content

class BaseAgent:
    """Base class for all agents in the system from scrap (3).py."""
    def __init__(self, name: str, description: str, model_name: str = Config.GPT4_MODEL, **kwargs): 
        self.name = name
        self.description = description
        self.model_name = model_name
        self.agent_type = kwargs.get("agent_type", "generic") 
        self.logger = logging.getLogger(self.__class__.__name__) 

        if not Config.OPENAI_API_KEY:
            self.logger.error("OPENAI_API_KEY not set in environment via Config.")
            raise ValueError("OPENAI_API_KEY not set.")
        self.llm = ChatOpenAI(model_name=model_name, openai_api_key=Config.OPENAI_API_KEY, temperature=0.2)

    def execute(self, input_data: Any) -> Any:
        raise NotImplementedError("Subclasses must implement this method")

    def _run_llm_chain(self, prompt_template: ChatPromptTemplate, input_vars: Dict = None) -> str:
        if input_vars is None:
            input_vars = {}
        chain = LLMChain(llm=self.llm, prompt=prompt_template)
        return chain.run(input_vars)

    def log_execution(self, input_summary: str, output_summary: str, start_time: float):
        end_time = time.time()
        self.logger.info(
            f"Agent '{self.name}' (Type: {self.agent_type}) executed. "
            f"Duration: {end_time - start_time:.2f}s"
        )


class ReviewAgent(BaseAgent):
    """Agent responsible for reviewing standards and extracting key elements."""
    def __init__(self):
        super().__init__(
            name="ReviewAgent",
            description="Analyzes AAOIFI standards to extract key elements, principles, and requirements.",
            model_name=Config.GPT4_MODEL
        )
        self.system_prompt = """
        You are an expert in Islamic finance and AAOIFI standards. Your task is to carefully review
        the provided standard document and extract the following key elements.
        Use clear Markdown headings for each section exactly as listed below (e.g., ## Core principles and objectives).
        It is crucial that you provide content under each of these specified headings.

        ## Core principles and objectives
        [Your extraction here]

        ## Key definitions and terminology
        [Your extraction here]

        ## Main requirements and procedures
        [Your extraction here]

        ## Compliance criteria and guidelines
        [Your extraction here]

        ## Practical implementation considerations
        [Your extraction here]

        Be thorough but concise.
        """

    def execute(self, standard: StandardDocument) -> Dict[str, Any]:
        start_time = time.time()
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"Standard Name: {standard.name}\n\nContent:\n{standard.content}")
        ])
        result_text = self._run_llm_chain(prompt)
        
        parsed_result = {
            "standard_name": standard.name,
            "review_result": result_text, 
            "core_principles": self._extract_section(result_text, "Core principles and objectives"),
            "key_definitions": self._extract_section(result_text, "Key definitions and terminology"),
            "main_requirements": self._extract_section(result_text, "Main requirements and procedures"),
            "compliance_criteria": self._extract_section(result_text, "Compliance criteria and guidelines"),
            "implementation_considerations": self._extract_section(result_text, "Practical implementation considerations")
        }
        self.log_execution(f"Standard: {standard.name}", parsed_result.get("core_principles","N/A"), start_time)
        return parsed_result

    def _extract_section(self, text: str, section_name: str) -> str:
        """Robustly extract a section from text using flexible regex for Markdown headings."""
        self.logger.debug(f"ReviewAgent: Attempting to extract section: '{section_name}'")
        escaped_section_name = re.escape(section_name)
        
        # Regex Explanation:
        # (?:^[ \t]*([#]{2,6})\s*)? : Optional start of line, optional whitespace, optional 2-6 hashes (capturing them), optional whitespace
        # ({escaped_section_name})  : The section name (case-insensitive)
        # \s*\n                     : Optional whitespace then a newline (heading must end with a newline for content to start below)
        # (.*?)                     : Capture content non-greedily
        # (?=...)                   : Positive lookahead for the end of the section
        #   (?:^[ \t]*\1\s*\w)       : Next line starts with the SAME captured hash level (e.g., ## if current was ##)
        #   | (?:^[ \t]*[#]{{m}}\s*\w) : Or next line starts with FEWER hashes (e.g., # if current was ##) - m is current_hashes - 1
        #   | \Z                      : Or end of string
        
        # Try with `## Section Name` specifically, as requested by the prompt
        pattern_str = (
            r"^[ \t]*(?:##\s*)" +          # Expect ##, optional space
            escaped_section_name +         # The section name
            r"\s*\n" +                     # Whitespace then newline (content must be on next line)
            r"(.*?)" +                     # Capture content (non-greedy)
            r"(?=(^[ \t]*##\s*\w|\Z))"     # Lookahead for next ## heading or EOS
        )
        pattern = re.compile(pattern_str, re.DOTALL | re.IGNORECASE | re.MULTILINE)
        match = pattern.search(text)

        if match:
            extracted_content = match.group(1).strip()
            self.logger.info(f"ReviewAgent: Successfully extracted section: '{section_name}'. Length: {len(extracted_content)}")
            if not extracted_content:
                self.logger.warning(f"ReviewAgent: Extracted section '{section_name}' is EMPTY (heading found, no content under it). Full text (first 500): {text[:500]}")
            return extracted_content
        else:
            self.logger.warning(f"ReviewAgent: Section '{section_name}' NOT FOUND with primary regex. Text (first 500): {text[:500]}")
            # Fallback: Try to find the heading without specific ## and grab content until two newlines
            fallback_pattern_str = (
                r"^[ \t]*" + escaped_section_name + r"\s*\n" +
                r"(.*?)" +
                r"(?=(\n\s*\n|[#]{2}))" # Until two newlines or next ##
            )
            fallback_pattern = re.compile(fallback_pattern_str, re.DOTALL | re.IGNORECASE | re.MULTILINE)
            fallback_match = fallback_pattern.search(text)
            if fallback_match:
                extracted_content = fallback_match.group(1).strip()
                self.logger.info(f"ReviewAgent: Successfully extracted section (via FALLBACK): '{section_name}'. Length: {len(extracted_content)}")
                if not extracted_content:
                     self.logger.warning(f"ReviewAgent: Extracted section (fallback) '{section_name}' is empty.")
                return extracted_content

            self.logger.error(f"ReviewAgent: Section '{section_name}' still NOT FOUND even with fallback.")
            return f"Section '{section_name}' not found or parsing error."

# ... (EnhancementAgent, ValidationAgent, FinalReportAgent from your MAI.py, assuming they are okay for now) ...
# ... (VectorDBManager, AAOIFIStandardsEnhancementSystem from your MAI.py) ...
# ... (safely_recreate_vector_database, process_pdfs_safe from your MAI.py) ...
class EnhancementAgent(BaseAgent):
    """Agent tasked with proposing modifications or enhancements to standards."""

    def __init__(self):
        super().__init__(
            name="EnhancementAgent",
            description="Proposes AI-driven modifications and enhancements to AAOIFI standards.",
            model_name=Config.GPT4_MODEL
        )

        self.system_prompt = """
        You are an AI expert specializing in Islamic finance and AAOIFI standards enhancement.
        Your task is to propose thoughtful modifications and enhancements to the standard based
        on the review provided.

        Consider the following aspects in your proposals. Use clear Markdown subheadings for each aspect (e.g., ### Clarity improvements). Ensure content is provided under each.
        ### Clarity improvements
        [Suggestions]
        ### Modern context adaptations
        [Suggestions]
        ### Technological integration
        [Suggestions]
        ### Cross-reference enhancements
        [Suggestions]
        ### Practical implementation
        [Suggestions]

        For each suggestion, provide:
        - The specific section or clause being enhanced (if applicable, otherwise general proposal)
        - The current text or concept (if applicable, very brief summary)
        - Your proposed modification or addition
        - A brief justification explaining the benefit of your enhancement

        Ensure all suggestions maintain strict compliance with Shariah principles.
        """

    def execute(self, review_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        review_text_summary = review_result.get("review_result", "No review summary available.")

        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"Standard Name: {review_result['standard_name']}\n\nSummary of Standard Review:\n{review_text_summary}")
        ])
        result_text = self._run_llm_chain(prompt)
        
        output = {
            "standard_name": review_result["standard_name"],
            "enhancement_proposals": result_text
        }
        self.log_execution(f"Review for {review_result['standard_name']}", result_text, start_time)
        return output

class ValidationAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="ValidationAgent",
            description="Validates proposed changes based on Shariah compliance and practicality.",
            model_name=Config.GPT4_MODEL
        )
        self.system_prompt = """
        You are a senior Shariah scholar and AAOIFI standards expert. Your role is to validate
        proposed enhancements. For each proposed enhancement, evaluate:
        1. Shariah Compliance
        2. Technical Accuracy
        3. Practical Applicability
        4. Consistency
        5. Value Addition
        For each proposal, provide: Your assessment (Approved/Rejected/Needs Modification), Justification, Suggested refinements if "Needs Modification".
        Structure your response clearly. Start with a main heading: ## Validation Assessment. Ensure content under this heading.
        """

    def execute(self, enhancement_result: Dict[str, Any], original_review: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        review_text_summary = original_review.get("review_result", "No review summary available.")
        enhancement_proposals_text = enhancement_result.get("enhancement_proposals", "No enhancement proposals available.")

        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"""
            Standard Name: {enhancement_result['standard_name']}
            Original Standard Review Summary:
            {review_text_summary}
            Proposed Enhancements to Validate:
            {enhancement_proposals_text}
            """)
        ])
        result_text = self._run_llm_chain(prompt)
        output = {
            "standard_name": enhancement_result["standard_name"],
            "validation_result": result_text
        }
        self.log_execution(f"Enhancements for {enhancement_result['standard_name']}", result_text, start_time)
        return output


class FinalReportAgent(BaseAgent): 
    def __init__(self):
        super().__init__(
            name="FinalReportAgent",
            description="Compiles all findings and recommendations into a comprehensive report.",
            model_name=Config.GPT4_MODEL
        )
        self.system_prompt = """
        You are a professional report writer specializing in Islamic finance standards. Your task is to
        compile all the findings, enhancements, and validations into a comprehensive, well-structured report
        in Markdown format. 
        
        Use the following main Markdown headings (e.g., ## Executive Summary) for each section. Ensure these exact headings are used and that substantial content is provided under each:
        - Executive Summary
        - Standard Overview
        - Key Findings from Review
        - Proposed Enhancements
        - Validation Results
        - Consolidated Recommendations
        - Implementation Considerations
        - Conclusion
        
        Write in a professional, clear, and objective style.
        """

    def execute(self, all_results: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"""
            Standard Name: {all_results['standard_name']}
            Full Text of Standard Review:
            {all_results.get('review_text', all_results.get('review_result', 'N/A'))}
            Full Text of Proposed Enhancements:
            {all_results.get('enhancements_text', all_results.get('enhancement_proposals', 'N/A'))}
            Full Text of Validation of Enhancements:
            {all_results.get('validation_text', all_results.get('validation_result', 'N/A'))}
            """)
        ])
        report_text = self._run_llm_chain(prompt)
        output = {
            "standard_name": all_results["standard_name"],
            "final_report": report_text
        }
        self.log_execution(f"All results for {all_results['standard_name']}", report_text, start_time)
        return output


class VectorDBManager(VectorDBManager): 
    def __init__(self, db_directory: str = None, collection_name: str = config.COLLECTION_NAME):
        super().__init__(db_directory, collection_name) 


class AAOIFIStandardsEnhancementSystem(AAOIFIStandardsEnhancementSystem): 
    def __init__(self):
        super().__init__()


def safely_recreate_vector_database(documents):
    embeddings = OpenAIEmbeddings(model=config.EMBEDDING_MODEL, openai_api_key=Config.OPENAI_API_KEY)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    random_str = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))
    base_db_parent_dir = "aaoifi_vector_db_versions"
    os.makedirs(base_db_parent_dir, exist_ok=True)
    new_db_directory = os.path.join(base_db_parent_dir, f"db_{timestamp}_{random_str}")

    logger.info(f"Creating new database in directory: {new_db_directory}")
    os.makedirs(new_db_directory, exist_ok=True)

    client = chromadb.PersistentClient(path=new_db_directory)
    collection = client.create_collection(name=config.COLLECTION_NAME)
    
    batch_size = 100
    num_batches = (len(documents) + batch_size - 1) // batch_size

    for i in range(0, len(documents), batch_size):
        batch_documents = documents[i:i+batch_size]
        current_batch_num = (i // batch_size) + 1
        logger.info(f"Processing batch {current_batch_num}/{num_batches} for new vector database...")
        texts = [doc["content"] for doc in batch_documents]
        ids = [f"{doc['metadata']['source']}_chunk_{doc['metadata']['chunk_id']}" for doc in batch_documents]
        if len(ids) != len(set(ids)):
            logger.warning(f"Warning: Duplicate IDs generated in batch {current_batch_num}. Appending index.")
            ids = [f"{id_}_{j}" for j, id_ in enumerate(ids)]
        metadatas = [doc["metadata"] for doc in batch_documents]

        if not texts: continue
        try:
            embeds = embeddings.embed_documents(texts)
            collection.add(embeddings=embeds, documents=texts, ids=ids, metadatas=metadatas)
        except Exception as e:
            logger.error(f"Error processing batch {current_batch_num}: {str(e)}")
            continue
    
    logger.info(f"Created new vector database in '{new_db_directory}'")
    config.DB_DIRECTORY = new_db_directory
    logger.info(f"Updated global config.DB_DIRECTORY to: {config.DB_DIRECTORY}")
    return client

def process_pdfs_safe():
    PDF_FOLDER = config.PDF_FOLDER
    if not os.path.exists(PDF_FOLDER) or not os.listdir(PDF_FOLDER):
        logger.error(f"PDF folder '{PDF_FOLDER}' is missing or empty.")
        return None
    all_documents = []
    pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.lower().endswith('.pdf')]
    if not pdf_files:
        logger.info(f"No PDF files found in '{PDF_FOLDER}'.")
        return None
    logger.info(f"Found {len(pdf_files)} PDF files.")
    for pdf_file in pdf_files:
        pdf_path = os.path.join(PDF_FOLDER, pdf_file)
        standard_name = os.path.splitext(pdf_file)[0]
        logger.info(f"Processing {pdf_file}...")
        raw_text = extract_text_from_pdf(pdf_path)
        cleaned_text = clean_text(raw_text)
        doc_chunks = split_text_into_chunks(cleaned_text, standard_name) 
        all_documents.extend(doc_chunks)
        logger.info(f"Extracted {len(doc_chunks)} chunks from {pdf_file}")

    if not all_documents: return None
    logger.info(f"Total chunks extracted: {len(all_documents)}")
    client = safely_recreate_vector_database(all_documents)
    return client

# --- NewBaseAgent, DocumentReviewAgent (stub), StandardAnalysisAgent, EnhancementAgentNew, ShariahComplianceAgent, ValidationAgentNew ---
# --- ReportGenerationAgent, VisualizationAgent, FeedbackAgent ---
# --- VectorDBManagerNew, AAOIFIStandardsSystem (New Orchestrator) ---
# --- load_sample_standard, visualize_results, run_demo, __main__ block ---
# --- All these will be pasted from the previous corrected response where they were defined ---

# NewBaseAgent for the user's new agent structure
class NewBaseAgent: 
    def __init__(self, name: str, description: str, agent_type: str, model_name: str = Config.GPT4_MODEL):
        self.name = name
        self.description = description
        self.agent_type = agent_type
        self.model_name = model_name
        self.logger = logging.getLogger(self.__class__.__name__) 

        if not Config.OPENAI_API_KEY:
            self.logger.error("OpenAI API key not found in Config.")
            raise ValueError("OpenAI API key not configured.")
        self.llm = ChatOpenAI(model_name=self.model_name, openai_api_key=Config.OPENAI_API_KEY, temperature=0.2)

    def _run_chain(self, messages: List[Any]) -> str:
        prompt = ChatPromptTemplate.from_messages(messages)
        chain = LLMChain(llm=self.llm, prompt=prompt)
        try:
            result = chain.run({}) 
        except Exception as e:
            self.logger.error(f"Error running LLM chain for agent {self.name}: {e}")
            return f"Error in LLM call: {e}"
        return result

    def log_execution(self, input_summary: str, output_summary: str, start_time: float):
        end_time = time.time()
        self.logger.info(
            f"Agent '{self.name}' (Type: {self.agent_type}) executed. "
            f"Duration: {end_time - start_time:.2f}s"
        )

    def _extract_section(self, text: str, section_name: str, heading_level_char: str = "#", min_hashes: int = 2) -> str:
        """Extract a section from text using flexible regex for headings."""
        self.logger.debug(f"NewBaseAgent: Attempting to extract section: '{section_name}' with marker {heading_level_char*min_hashes}")
        
        # Prepare section_name for regex: escape it, and replace underscores with spaces
        processed_section_name_for_regex = re.escape(section_name.replace('_', ' '))
        
        # Construct regex for heading marker e.g. ## or ###
        marker_regex = re.escape(heading_level_char) * min_hashes

        # Pattern Explanation:
        # ^[ \t]*                      : Start of a line, optional leading whitespace.
        # {marker_regex}\s*            : The specific heading marker (e.g., ## or ###), followed by optional space.
        # {processed_section_name_for_regex} : The section name itself (case insensitive).
        # \s*\n                        : Optional whitespace then a newline (content must start on the line AFTER the heading).
        # (.*?)                        : Capture the content (non-greedy).
        # (?=                          : Positive lookahead for the end of the section:
        #    ^[ \t]*{marker_regex}\s*\w : Next line starts with the SAME heading marker pattern.
        #    | \Z                       : OR it's the end of the string.
        # )
        pattern_str = (
            r"^[ \t]*" + marker_regex + r"\s*" +
            processed_section_name_for_regex +
            r"\s*\n" +
            r"(.*?)" +
            r"(?=(^[ \t]*" + marker_regex + r"\s*\w|\Z))"
        )
        pattern = re.compile(pattern_str, re.DOTALL | re.IGNORECASE | re.MULTILINE)
        match = pattern.search(text)
        
        if match:
            extracted = match.group(1).strip()
            self.logger.info(f"NewBaseAgent: Successfully extracted section: '{section_name}'. Length: {len(extracted)}")
            if not extracted:
                 self.logger.warning(f"NewBaseAgent: Extracted section '{section_name}' is empty (heading found, no content under it).")
            return extracted
        
        self.logger.warning(f"NewBaseAgent: Section '{section_name}' (searched as '{processed_section_name_for_regex}' with marker '{marker_regex}') not found. Text searched (first 500 chars): {text[:500]}")
        return f"Section '{section_name}' not found."

class DocumentReviewAgent(NewBaseAgent): # This is a stub that uses the original ReviewAgent
    def __init__(self):
        super().__init__("Document Review Agent", "Reviews standard documents using original ReviewAgent", "review_stub")
    def execute(self, standard: StandardDocument) -> Dict[str, Any]:
        self.logger.info(f"Executing DocumentReviewAgent (stub using original ReviewAgent) for {standard.name}")
        original_review_agent = ReviewAgent() 
        return original_review_agent.execute(standard)

class StandardAnalysisAgent(NewBaseAgent):
    def __init__(self):
        super().__init__("Standard Analysis Agent", "Analyzes standards for challenges and improvements", "analysis", model_name=Config.GPT35_MODEL)
        self.system_prompt = """You are an AI analyst. Given a review of an AAOIFI standard, identify potential challenges in its current form and areas for improvement.
        Respond using the following Markdown headings for each section. Ensure substantial content under each heading:
        ## Challenges
        [List challenges here]
        ## Improvement Areas
        [List improvement areas here]
        """
    def execute(self, review_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"Standard Name: {review_result['standard_name']}\nReview Summary (first 1000 chars): {review_result.get('review_result', 'N/A')[:1000]}")
        ]
        analysis_text = self._run_chain(messages)
        result = {
            "standard_name": review_result['standard_name'],
            "full_analysis_text": analysis_text,
            "challenges": self._extract_section(analysis_text, "Challenges", min_hashes=2),
            "improvement_areas": self._extract_section(analysis_text, "Improvement Areas", min_hashes=2)
        }
        self.log_execution(f"Review for {review_result['standard_name']}", analysis_text, start_time)
        return result

class EnhancementAgentNew(NewBaseAgent): 
    def __init__(self):
        super().__init__("Enhancement Agent (New)", "Proposes enhancements based on review and analysis", "enhancement")
        self.system_prompt = """You are an AI expert for AAOIFI standards. Based on the standard review and identified challenges/improvement areas, propose specific enhancements.
        Organize proposals into the following categories using clear Markdown subheadings (e.g., ### clarity_improvements). Ensure each category heading is EXACTLY as written below (using underscores where shown AND three hashes ###) and on its own line, followed by substantial content on the next lines:
        ### clarity_improvements
        [Suggestions...]
        ### modern_adaptations
        [Suggestions...]
        ### tech_integration
        [Suggestions...]
        ### cross_references
        [Suggestions...]
        ### implementation_guidance
        [Suggestions...]
        For each proposal under these categories: specify the section, current concept, proposed modification, and justification."""

    def execute(self, review_result: Dict[str, Any], analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"""
            Standard Name: {review_result['standard_name']}
            Review Summary (first 1000 chars): {review_result.get('review_result', 'N/A')[:1000]}... 
            Identified Challenges: {analysis_result.get('challenges', 'N/A')}
            Identified Improvement Areas: {analysis_result.get('improvement_areas', 'N/A')}
            Please generate enhancement proposals ensuring to use the exact specified ### subheadings for each category and provide substantial content for each.
            """)
        ]
        enhancement_text = self._run_chain(messages)
        
        result = {
            "standard_name": review_result['standard_name'],
            "enhancement_proposals": enhancement_text, 
            "clarity_improvements": self._extract_section(enhancement_text, "clarity_improvements", min_hashes=3),
            "modern_adaptations": self._extract_section(enhancement_text, "modern_adaptations", min_hashes=3),
            "tech_integration": self._extract_section(enhancement_text, "tech_integration", min_hashes=3),
            "cross_references": self._extract_section(enhancement_text, "cross_references", min_hashes=3),
            "implementation_guidance": self._extract_section(enhancement_text, "implementation_guidance", min_hashes=3)
        }
        self.log_execution(f"Analysis for {review_result['standard_name']}", enhancement_text, start_time)
        return result

class ShariahComplianceAgent(NewBaseAgent):
    def __init__(self):
        super().__init__("Shariah Compliance Agent", "Assesses Shariah compliance of proposals", "shariah_compliance", model_name=Config.GPT4_MODEL)
        self.system_prompt = """You are a Shariah scholar. Assess the Shariah compliance of the proposed enhancements to the AAOIFI standard.
        Provide a general shariah_assessment summary under a heading '## Shariah Assessment Summary'.
        Then, for each specific category of enhancement listed below, provide an overall_ruling (Approved, Conditionally Approved, Requires Modification, Rejected) and a brief justification.
        Format this as a Markdown list, with each item clearly starting with the category name (using underscores) followed by a colon and the ruling, then a hyphen and justification. Example:
        - clarity_improvements: Approved - The proposed changes enhance understanding without violating Shariah principles.
        - modern_adaptations: Conditionally Approved - Adaptations are acceptable if X condition is met.
        - tech_integration: Requires Modification - Current proposal for Y needs adjustment Z to be compliant.
        - cross_references: Approved - Beneficial for consistency.
        - implementation_guidance: Approved - Practical and compliant.
        Ensure you provide a ruling for all five categories: clarity_improvements, modern_adaptations, tech_integration, cross_references, implementation_guidance.
        """

    def execute(self, enhancement_result: Dict[str, Any], review_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        
        enhancement_summaries_for_prompt = {}
        enhancement_categories_keys = [
            "clarity_improvements", "modern_adaptations", 
            "tech_integration", "cross_references", "implementation_guidance"
        ]
        
        prompt_human_content = f"""
        Standard Name: {enhancement_result['standard_name']}
        Original Review Summary (excerpt): {review_result.get('review_result', 'N/A')[:500]}...
        
        Proposed Enhancements Summaries (Note: if a category below indicates content was 'not properly extracted', it implies an issue from the previous agent. Base your assessment on the overall enhancement proposals text provided below if necessary, or state if assessment is not possible for that category):
        """
        for key in enhancement_categories_keys:
            content = enhancement_result.get(key, "Category content not available or not extracted.") 
            if isinstance(content, str) and (content.startswith("Section") and "not found" in content): 
                 enhancement_summaries_for_prompt[key] = f"Content for {key} was not properly extracted by the previous agent. Please refer to full proposals text."
            else:
                 enhancement_summaries_for_prompt[key] = (str(content)[:300] + "..." if len(str(content)) > 300 else str(content))
            prompt_human_content += f"\n{key.replace('_',' ').title()}:\n{enhancement_summaries_for_prompt[key]}\n"
        
        # Include full enhancement proposals text for context
        full_proposals_text = enhancement_result.get('enhancement_proposals', 'N/A')
        prompt_human_content += f"\nFull Text of All Enhancement Proposals (for context):\n{full_proposals_text[:2000]}...\n" # Truncate for prompt length
        
        prompt_human_content += "\nPlease provide Shariah assessment as per the specified format (Markdown list with category_name: RULING - Justification for all 5 categories)."

        messages = [ SystemMessage(content=self.system_prompt), HumanMessage(content=prompt_human_content) ]
        shariah_text = self._run_chain(messages)

        overall_rulings = {}
        for key in enhancement_categories_keys:
            pattern_category_name = key 
            # Regex to find "category_name: RULING - Justification"
            # Making it case insensitive for category name.
            # Allows optional markdown list marker '-' or '*'
            # Ensures RULING is captured as one or more words.
            pattern = re.compile(rf"^\s*[-*]?\s*{pattern_category_name}\s*:\s*([A-Za-z\s]+?)\s*-\s*(.*)", re.IGNORECASE | re.MULTILINE)
            match = pattern.search(shariah_text)
            if match:
                ruling = match.group(1).strip()
                # justification = match.group(2).strip() # Justification can be captured if needed elsewhere
                overall_rulings[key] = ruling
                self.logger.info(f"Shariah ruling parsed for '{key}': {overall_rulings[key]}")
            else:
                self.logger.warning(f"Could not parse ruling for category '{key}' from Shariah assessment text. Full text of Shariah assessment (first 500 char): {shariah_text[:500]}")
                overall_rulings[key] = "Not specifically assessed" 

        result = {
            "standard_name": enhancement_result['standard_name'],
            "shariah_assessment": self._extract_section(shariah_text, "Shariah Assessment Summary", min_hashes=2) or shariah_text, 
            "overall_ruling": overall_rulings
        }
        self.log_execution(f"Enhancements for {enhancement_result['standard_name']}", shariah_text, start_time)
        return result


class ValidationAgentNew(NewBaseAgent): 
    def __init__(self):
        super().__init__("Validation Agent (New)", "Validates practical aspects of proposals", "validation")
        self.system_prompt = """You are an AAOIFI standards expert. Validate the proposed enhancements considering their Shariah assessment.
        Focus on practical applicability, consistency, and value addition.
        Provide an overall validation_result summary under a heading '## Overall Validation Summary'.
        Then, for each category of enhancement, provide an implementation_assessment under subheadings like '### Clarity Improvements Assessment'.
        Use the exact category names (e.g., "Clarity Improvements Assessment", "Modern Adaptations Assessment", etc.) for the subheadings. Ensure substantial content for each.
        """
    def execute(self, enhancement_result: Dict[str, Any], shariah_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"""
            Standard Name: {enhancement_result['standard_name']}
            Proposed Enhancements (Full text, may be long): {enhancement_result.get('enhancement_proposals', 'N/A')[:2000]}...
            Shariah Assessment Summary: {shariah_result.get('shariah_assessment', 'N/A')}
            Shariah Rulings per Category: {json.dumps(shariah_result.get('overall_ruling',{}), indent=2)}
            Please provide practical validation using the specified heading structure and ensure substantial content under each section.
            """)
        ]
        validation_text = self._run_chain(messages)
        
        result = {
            "standard_name": enhancement_result['standard_name'],
            "validation_result": self._extract_section(validation_text, "Overall Validation Summary", min_hashes=2) or validation_text, 
            "implementation_assessments": { 
                "clarity_improvements": self._extract_section(validation_text, "Clarity Improvements Assessment", min_hashes=3),
                "modern_adaptations": self._extract_section(validation_text, "Modern Adaptations Assessment", min_hashes=3),
                "tech_integration": self._extract_section(validation_text, "Tech Integration Assessment", min_hashes=3),
                "cross_references": self._extract_section(validation_text, "Cross References Assessment", min_hashes=3),
                "implementation_guidance": self._extract_section(validation_text, "Implementation Guidance Assessment", min_hashes=3),
            }
        }
        self.log_execution(f"Shariah assessment for {enhancement_result['standard_name']}", validation_text, start_time)
        return result

class ReportGenerationAgent(NewBaseAgent): 
    def __init__(self):
        super().__init__(
            name="Report Generation Agent",
            description="Synthesizes findings and recommendations into comprehensive reports.",
            agent_type="report"
        )
        self.system_prompt = """
        You are an expert report writer specializing in Islamic finance standards. Your task is to 
        synthesize all findings, analyses, and recommendations into a comprehensive, well-structured 
        report that presents the key insights in a clear and actionable format.

        Your report should include the following sections, using clear Markdown headings (e.g., ## Executive Summary). Ensure these headings are EXACTLY as listed and that substantial content is provided for each:
        - Executive Summary
        - Standard Analysis
        - Enhancement Recommendations
        - Validation Results
        - Implementation Roadmap
        - Appendices (if applicable, mention what could be in appendices)
        
        Format the report professionally. Use concise, precise language.
        The report should be comprehensive but accessible to Islamic finance professionals.
        """
    
    def execute(self, 
                review_result: Dict[str, Any], 
                analysis_result: Dict[str, Any],
                enhancement_result: Dict[str, Any],
                shariah_result: Dict[str, Any],
                validation_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        standard_name = review_result.get("standard_name", "Unknown Standard")
        
        core_principles = review_result.get("core_principles", "Not available")
        main_requirements = review_result.get("main_requirements", "Not available")
        challenges = analysis_result.get("challenges", "Not available")
        improvement_areas = analysis_result.get("improvement_areas", "Not available")
        # enhancement_proposals_full = enhancement_result.get("enhancement_proposals", "Not available") # Full text
        shariah_assessment_summary = shariah_result.get("shariah_assessment", "Not available")
        shariah_rulings_category = shariah_result.get("overall_ruling", {})
        validation_assessment_summary = validation_result.get("validation_result", "Not available")
        implementation_assessments_category = validation_result.get("implementation_assessments", {})

        enhancement_summary_for_prompt = "Details for Enhancement Recommendations section:\n"
        for cat_key in ["clarity_improvements", "modern_adaptations", "tech_integration", "cross_references", "implementation_guidance"]:
            enhancement_summary_for_prompt += f"\n#### {cat_key.replace('_',' ').title()}\n{enhancement_result.get(cat_key, 'N/A')}\n"

        shariah_summary_for_prompt = f"""
        Overall Shariah Assessment Summary: {shariah_assessment_summary}
        Rulings per Category: {json.dumps(shariah_rulings_category, indent=2)}
        """

        validation_summary_for_prompt = f"""
        Overall Validation Summary: {validation_assessment_summary}
        Implementation Assessments per Category: {json.dumps(implementation_assessments_category, indent=2)}
        """

        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"""
            Standard Name: {standard_name}
            
            Data from ReviewAgent (for 'Standard Overview' and 'Key Findings from Review' sections):
            Core Principles: {core_principles}
            Main Requirements: {main_requirements}
            Key Definitions: {review_result.get("key_definitions", "N/A")}
            Compliance Criteria: {review_result.get("compliance_criteria", "N/A")}
            Implementation Considerations (Original): {review_result.get("implementation_considerations", "N/A")}
            Full Review Text: {review_result.get("review_result", "N/A")[:1000]}...
            
            Data from StandardAnalysisAgent (for 'Standard Analysis' section, e.g. challenges):
            Identified Challenges: {challenges}
            Identified Improvement Areas: {improvement_areas}
            
            Data from EnhancementAgentNew (for 'Enhancement Recommendations' section):
            {enhancement_summary_for_prompt}
            
            Data from ShariahComplianceAgent (for 'Validation Results' section):
            {shariah_summary_for_prompt}
            
            Data from ValidationAgentNew (for 'Validation Results' and 'Implementation Roadmap' sections):
            {validation_summary_for_prompt}
            
            Please generate a comprehensive report synthesizing all this information.
            Ensure the report strictly follows the requested Markdown heading structure for each section and provides substantial, well-organized content under each.
            For 'Enhancement Recommendations', list the detailed proposals under their respective categories.
            For 'Validation Results', incorporate both Shariah compliance and practical validation findings.
            """)
        ]
        report_text = self._run_chain(messages)
        result = {
            "standard_name": standard_name,
            "full_report": report_text,
            "executive_summary": self._extract_section(report_text, "Executive Summary", min_hashes=2),
            "standard_analysis": self._extract_section(report_text, "Standard Analysis", min_hashes=2),
            "enhancement_recommendations": self._extract_section(report_text, "Enhancement Recommendations", min_hashes=2),
            "validation_results": self._extract_section(report_text, "Validation Results", min_hashes=2),
            "implementation_roadmap": self._extract_section(report_text, "Implementation Roadmap", min_hashes=2)
        }
        self.log_execution(f"All results for {standard_name}", report_text, start_time)
        return result

class VisualizationAgent(NewBaseAgent): 
    def __init__(self):
        super().__init__(
            name="Visualization Agent",
            description="Creates visual representations of findings and recommendations.",
            agent_type="visualization"
        )
        self.system_prompt = """
        You are an expert in data visualization and information design specializing in financial standards.
        Your task is to design clear and informative visualizations that effectively communicate the 
        key findings and recommendations from the analysis.

        For the given analysis results, create text descriptions and chart specifications for the following, using clear Markdown headings for each (e.g., ## Enhancement Impact Matrix). Ensure these headings are EXACTLY as listed and have substantial content:
        - Enhancement Impact Matrix
        - Shariah Compliance Visualization
        - Implementation Roadmap Timeline
        - Stakeholder Impact Analysis
        For each visualization, provide: A clear title and description, Detailed specification of the visualization type and key elements, The data structure needed (example format), Brief interpretation.
        Design visualizations that are both informative and accessible.
        """
    
    def execute(self, 
                enhancement_result: Dict[str, Any],
                shariah_result: Dict[str, Any],
                validation_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        standard_name = enhancement_result.get("standard_name", "Unknown Standard")
        
        enhancement_summary_prompt = {
            key: (enhancement_result.get(key, "N/A")[:100] + "...") 
            for key in ["clarity_improvements", "modern_adaptations", "tech_integration", "cross_references", "implementation_guidance"]
        }
        shariah_summary_prompt = shariah_result.get("overall_ruling", {})
        validation_summary_prompt = validation_result.get("implementation_assessments", {})

        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"""
            Standard Name: {standard_name}
            Enhancement Categories Summary: {json.dumps(enhancement_summary_prompt, indent=2)}
            Shariah Compliance Rulings Summary: {json.dumps(shariah_summary_prompt, indent=2)}
            Implementation Assessments Summary: {json.dumps(validation_summary_prompt, indent=2)}
            Please generate visualization specifications based on this information.
            Ensure you use the specified Markdown headings for each visualization type and provide substantial content under each.
            """)
        ]
        visualization_text = self._run_chain(messages)
        result = {
            "standard_name": standard_name,
            "visualization_specifications": visualization_text,
            "enhancement_impact_matrix": self._extract_section(visualization_text, "Enhancement Impact Matrix", min_hashes=2),
            "shariah_compliance_visualization": self._extract_section(visualization_text, "Shariah Compliance Visualization", min_hashes=2),
            "implementation_roadmap_timeline": self._extract_section(visualization_text, "Implementation Roadmap Timeline", min_hashes=2),
            "stakeholder_impact_analysis": self._extract_section(visualization_text, "Stakeholder Impact Analysis", min_hashes=2)
        }
        self.log_execution(f"Results for {standard_name}", visualization_text, start_time)
        return result

class FeedbackAgent(NewBaseAgent): 
    def __init__(self):
        super().__init__(
            name="Feedback Agent",
            description="Processes stakeholder feedback and suggests refinements to proposals.",
            agent_type="feedback"
        )
        self.system_prompt = """
        You are an expert facilitator specializing in stakeholder feedback collection and integration
        for Islamic finance standards. Your role is to process feedback on proposed standard enhancements
        and suggest refinements based on stakeholder input.

        When processing feedback, provide output under the following Markdown headings (e.g., ## Stakeholder Categories). Ensure these headings are EXACTLY as listed and have substantial content:
        - Stakeholder Categories
        - Feedback Patterns and Themes
        - Feedback Validity Analysis
        - Recommended Refinements
        - Feedback Incorporation Process Suggestions
        
        Focus on constructive integration of feedback while maintaining the core objectives
        of the standard and ensuring Shariah compliance.
        """
    
    def execute(self, feedback: str, enhancement_result: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        standard_name = enhancement_result.get("standard_name", "Unknown Standard")
        enhancement_proposals = enhancement_result.get("enhancement_proposals", "Not Available")
        
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"""
            Standard Name: {standard_name}
            Original Enhancement Proposals (Full Text):
            {enhancement_proposals}
            
            Stakeholder Feedback Provided:
            {feedback}
            
            Please analyze this feedback and suggest refinements to the proposals, structuring your response with the requested Markdown headings and ensure substantial content under each.
            """)
        ]
        feedback_analysis = self._run_chain(messages)
        result = {
            "standard_name": standard_name,
            "feedback_analysis": feedback_analysis, # Full text
            "stakeholder_categories": self._extract_section(feedback_analysis, "Stakeholder Categories", min_hashes=2),
            "feedback_patterns": self._extract_section(feedback_analysis, "Feedback Patterns and Themes", min_hashes=2),
            "feedback_validity": self._extract_section(feedback_analysis, "Feedback Validity Analysis", min_hashes=2),
            "recommended_refinements": self._extract_section(feedback_analysis, "Recommended Refinements", min_hashes=2),
            "incorporation_process": self._extract_section(feedback_analysis, "Feedback Incorporation Process Suggestions", min_hashes=2)
        }
        self.log_execution(f"Feedback for {standard_name}", feedback_analysis, start_time)
        return result

class VectorDBManagerNew: 
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        if not Config.OPENAI_API_KEY:
            self.logger.error("OpenAI API Key not found in Config for VectorDBManagerNew.")
            raise ValueError("OpenAI API Key not configured.")

        self.client = chromadb.PersistentClient(path=Config.DB_DIRECTORY) 
        self.embeddings = OpenAIEmbeddings(
            model=Config.EMBEDDING_MODEL,
            openai_api_key=Config.OPENAI_API_KEY
        )
        try:
            self.collection = self.client.get_or_create_collection(name=Config.COLLECTION_NAME)
            self.logger.info(f"VectorDBManagerNew: Connected to/created collection: {Config.COLLECTION_NAME} at {Config.DB_DIRECTORY}")
        except Exception as e: 
            self.logger.error(f"VectorDBManagerNew: Error getting/creating collection: {e}")
            raise
    
    def add_document(self, standard: StandardDocument) -> List[str]:
        doc_chunks = DocumentProcessor.split_text_into_chunks(standard.content, standard.name) 
        if not doc_chunks:
            self.logger.warning(f"No chunks generated for document {standard.name}. Skipping add.")
            return []

        chunk_texts = [chunk["content"] for chunk in doc_chunks]
        chunk_metadata = [chunk["metadata"] for chunk in doc_chunks]
        chunk_ids = [str(uuid.uuid4()) for _ in range(len(doc_chunks))]
        
        try:
            embeddings_list = self.embeddings.embed_documents(chunk_texts) 
        except Exception as e:
            self.logger.error(f"Error generating embeddings for {standard.name}: {e}")
            return []
            
        self.collection.add(
            embeddings=embeddings_list,
            documents=chunk_texts,
            metadatas=chunk_metadata,
            ids=chunk_ids
        )
        self.logger.info(f"Added {len(doc_chunks)} chunks from {standard.name} to vector database")
        return chunk_ids
    
    def search_standards(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        try:
            query_embedding = self.embeddings.embed_query(query)
        except Exception as e:
            self.logger.error(f"Error generating query embedding: {e}")
            return []

        results = self.collection.query(query_embeddings=[query_embedding], n_results=top_k)
        
        if not results or not results.get("documents") or not results["documents"][0]:
            return []

        documents = results["documents"][0]
        metadatas = results["metadatas"][0]
        distances = results["distances"][0]
        result_list = []
        for i in range(len(documents)):
            result_list.append({
                "content": documents[i],
                "metadata": metadatas[i],
                "relevance": 1 - distances[i] if distances[i] is not None else 0 
            })
        return result_list

class AAOIFIStandardsSystem:
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.logger.info("Initializing AAOIFI Standards Multi-Agent System (New Orchestrator)")
        
        self.review_agent = DocumentReviewAgent()
        self.analysis_agent = StandardAnalysisAgent()
        self.enhancement_agent = EnhancementAgentNew() 
        self.shariah_agent = ShariahComplianceAgent()
        self.validation_agent = ValidationAgentNew() 
        self.report_agent = ReportGenerationAgent()
        self.visualization_agent = VisualizationAgent()
        self.feedback_agent = FeedbackAgent()
        
        self.vector_db = VectorDBManagerNew() 
        
        os.makedirs(Config.OUTPUT_DIR, exist_ok=True)
        self.logger.info("System initialization complete (New Orchestrator)")
    
    def process_standard(self, standard: StandardDocument) -> Dict[str, Any]:
        self.logger.info(f"Beginning processing of standard: {standard.name} (New Orchestrator)")
        
        self.vector_db.add_document(standard) 
        
        review_result = self.review_agent.execute(standard)
        analysis_result = self.analysis_agent.execute(review_result)
        enhancement_result = self.enhancement_agent.execute(review_result, analysis_result)
        shariah_result = self.shariah_agent.execute(enhancement_result, review_result)
        validation_result = self.validation_agent.execute(enhancement_result, shariah_result)
        report_result = self.report_agent.execute(review_result, analysis_result, enhancement_result, shariah_result, validation_result)
        visualization_result = self.visualization_agent.execute(enhancement_result, shariah_result, validation_result)
        
        final_result = {
            "standard_name": standard.name, "review": review_result, "analysis": analysis_result,
            "enhancement": enhancement_result, "shariah_assessment": shariah_result,
            "validation": validation_result, "report": report_result, "visualizations": visualization_result
        }
        self._save_results(final_result, suffix="new_orchestrator_results")
        self.logger.info(f"Completed processing of standard: {standard.name} (New Orchestrator)")
        return final_result
    
    def incorporate_feedback(self, feedback: str, enhancement_result: Dict[str, Any]) -> Dict[str, Any]:
        self.logger.info("Processing stakeholder feedback (New Orchestrator)")
        if enhancement_result is None:
            enhancement_result = {"standard_name": "Unknown (from feedback)", "enhancement_proposals": "Not available due to prior error"}
            self.logger.warning("Enhancement result was None for feedback incorporation. Using placeholders.")

        feedback_result = self.feedback_agent.execute(feedback, enhancement_result)
        self._save_results(feedback_result, suffix="new_orchestrator_feedback") 
        return feedback_result
    
    def _save_results(self, results: Dict[str, Any], suffix: str = "results") -> None:
        standard_name = results.get("standard_name", "unknown_standard")
        sanitized_name = re.sub(r'[^\w\-_\.]', '_', standard_name)
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        output_path = os.path.join(Config.OUTPUT_DIR, f"{sanitized_name}_{suffix}_{timestamp}.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        self.logger.info(f"Results saved to {output_path}")

def load_sample_standard() -> StandardDocument:
    sample_content = """
    AAOIFI Shariah Standard No. X: Murabahah to the Purchase Orderer

    1. Scope of the Standard
    This standard covers Murabahah to the Purchase Orderer transactions as practiced by Islamic financial institutions, including the conditions, procedures, rules, and modern applications. It does not cover simple Murabahah transactions that do not involve a prior promise to purchase.

    2. Definition of Murabahah to the Purchase Orderer
    Murabahah to the Purchase Orderer is a transaction where an Islamic financial institution (IFI) purchases an asset based on a promise from a customer to buy the asset from the institution on Murabahah terms (cost plus profit) after the institution has purchased it.

    3. Shariah Requirements for Murabahah to the Purchase Orderer
    3.1 The IFI must acquire ownership of the asset before selling it to the customer.
    3.2 The IFI must bear the risks of ownership during the period between purchasing the asset and selling it to the customer.
    3.3 The cost price and markup must be clearly disclosed to the customer.
    3.4 The customer's promise to purchase is morally binding but not legally enforceable as a sale contract.
    3.5 The Murabahah sale contract can only be executed after the IFI has acquired ownership of the asset.

    4. Procedures for Murabahah to the Purchase Orderer
    4.1 The customer identifies the asset they wish to purchase and requests the IFI to purchase it.
    4.2 The IFI and customer enter into a promise agreement, where the customer promises to purchase the asset after the IFI acquires it.
    4.3 The IFI purchases the asset from the supplier.
    4.4 The IFI informs the customer that it has acquired the asset and offers to sell it on Murabahah terms.
    4.5 The customer accepts the offer, and a Murabahah sale contract is executed.
    4.6 The customer pays the agreed price, either in installments or as a lump sum.

    5. Modern Applications and Issues
    5.1 Appointment of the customer as agent: The IFI may appoint the customer as its agent to purchase the asset on its behalf, provided that the customer acts in a genuine agency capacity.
    5.2 Third-party guarantees: Independent third parties may provide guarantees to protect against negligence or misconduct.
    5.3 Late payment: The IFI may require the customer to donate to charity in case of late payment, but may not benefit from these amounts.
    5.4 Rebate for early settlement: The IFI may voluntarily give a rebate for early settlement, but this cannot be stipulated in the contract.

    6. Shariah Rulings on Specific Murabahah Issues
    6.1 It is not permissible to roll over a Murabahah financing by extending the payment period in exchange for an increase in the amount owed.
    6.2 Currency exchange (sarf) must be completed before the Murabahah transaction when purchasing assets in a different currency.
    6.3 Conventional insurance on Murabahah assets should be avoided in favor of Takaful (Islamic insurance) when available.

    7. Documentation Requirements
    7.1 Promise document: Detailing the customer's promise to purchase the asset.
    7.2 Agency agreement (if applicable): Appointing the customer as agent for purchasing the asset.
    7.3 Murabahah sale contract: Documenting the actual sale transaction.
    7.4 Security documents: Including collateral, guarantees, or pledges to secure the payment.
    """
    return StandardDocument(name="Murabahah Standard X", content=sample_content)


def visualize_results(results: Dict[str, Any]) -> None:
    if not results:
        logger.error("No results provided for visualization")
        return
    standard_name = results.get("standard_name", "Unknown Standard")
    ipython_available = False
    try:
        shell = get_ipython().__class__.__name__
        if shell == 'ZMQInteractiveShell' or shell == 'TerminalInteractiveShell':
            ipython_available = True
    except NameError:
        pass # Not in IPython

    try:
        report_data = results.get("report", {})
        executive_summary_text = report_data.get("executive_summary", f"Section 'Executive Summary' not found for {standard_name}.")
        
        if ipython_available:
            display(Markdown(f"## Executive Summary for {standard_name}"))
            display(Markdown(executive_summary_text))
        else:
            print(f"\n## Executive Summary for {standard_name}\n{executive_summary_text}\n")

        shariah_assessment_data = results.get("shariah_assessment", {})
        rulings_data = shariah_assessment_data.get("overall_ruling") 
        
        if rulings_data and isinstance(rulings_data, dict) and any(val not in ["Not specifically assessed", f"Section '{key}' not found or parsing error."] for key, val in rulings_data.items()):
            df_data = {'Category': [], 'Ruling': []}
            for cat, rul in rulings_data.items():
                if rul and not (rul == "Not specifically assessed" or "not found" in rul): 
                    df_data['Category'].append(cat.replace('_', ' ').title()) 
                    df_data['Ruling'].append(rul)
            
            if not df_data['Category']: 
                logger.info("No actual Shariah rulings (Approved, Conditionally Approved, etc.) to visualize after filtering.")
                if all(val == "Not specifically assessed" or "not found" in val for val in rulings_data.values()):
                     print(f"All Shariah ruling categories for {standard_name} were 'Not specifically assessed' or had parsing errors. No chart will be generated for specific rulings.")
                return

            df = pd.DataFrame(df_data)
            ruling_map = {'Approved': 3, 'Conditionally Approved': 2, 'Requires Modification': 1, 'Rejected': 0, 'Not specifically assessed': 1.5, 'N/A': 0.5 }
            df['Score'] = df['Ruling'].map(lambda x: ruling_map.get(x, 1.5))
            
            plt.figure(figsize=(12, 8)) 
            bar_colors = ['green' if s >= 2.5 else 'yellowgreen' if s >= 1.8 else 'orange' if s >= 1.2 else 'coral' if s >= 0.8 else 'red' for s in df['Score']]
            bars = plt.bar(df['Category'], df['Score'], color=bar_colors)
            plt.title(f'Shariah Compliance Assessment for {standard_name}', fontsize=14)
            plt.xlabel('Enhancement Category', fontsize=12)
            plt.ylabel('Compliance Level (Numeric Score)', fontsize=12)
            plt.xticks(rotation=30, ha='right', fontsize=10) 
            
            unique_scores_in_data = sorted(list(set(df['Score'])))
            yticks_locs, yticks_labels = [], []
            score_to_label_map = {v: k for k, v in ruling_map.items()}
            
            # Ensure all defined ruling map levels are present for context
            for score_val_map, label_map in sorted(ruling_map.items(), key=lambda item: item[1]):
                 if score_val_map not in yticks_locs: # Add if unique score
                    yticks_locs.append(score_val_map) # Use the score from map for location
                    yticks_labels.append(label_map)   # Use the label from map
            
            # Add any other scores present in the data if not covered by ruling_map defaults
            for score_val_data in unique_scores_in_data:
                if score_val_data not in yticks_locs:
                    yticks_locs.append(score_val_data)
                    yticks_labels.append(score_to_label_map.get(score_val_data, f"Score {score_val_data:.1f}"))

            # Sort ticks by location
            sorted_ticks_combined = sorted(list(set(zip(yticks_locs, yticks_labels))), key=lambda x: x[0])
            final_yticks_locs = [loc for loc, lab in sorted_ticks_combined]
            final_yticks_labels = [lab for loc, lab in sorted_ticks_combined]

            plt.yticks(final_yticks_locs, final_yticks_labels, fontsize=10)
            plt.ylim(bottom=min(-0.2, min(final_yticks_locs)-0.2 if final_yticks_locs else -0.2) , top=max(3.2, max(final_yticks_locs)+0.2 if final_yticks_locs else 3.2))
            plt.grid(axis='y', linestyle='--', alpha=0.7)
            plt.tight_layout() 
            for bar_obj, ruling_text in zip(bars, df['Ruling']): 
                plt.text(bar_obj.get_x() + bar_obj.get_width()/2., bar_obj.get_height() + 0.05, 
                         ruling_text, ha='center', va='bottom', fontsize=9, color='black')
            plt.show()
        elif rulings_data and all(val == "Not specifically assessed" or "not found" in str(val) for val in rulings_data.values()):
            logger.info(f"All Shariah ruling categories for {standard_name} were 'Not specifically assessed' or had parsing errors. No specific ruling chart will be generated.")
            if ipython_available:
                display(Markdown(f"_Note: All Shariah enhancement categories for **{standard_name}** were 'Not specifically assessed' by the ShariahComplianceAgent or had parsing issues. No specific compliance chart generated._"))
            else:
                print(f"\nNote: All Shariah enhancement categories for {standard_name} were 'Not specifically assessed' or had parsing issues. No specific compliance chart generated.\n")
        else:
            logger.info("No 'overall_ruling' data or no actual rulings available for Shariah compliance visualization.")

    except ImportError: 
        logger.warning("Matplotlib or Pandas not installed. Skipping visualization that requires them.")
    except Exception as e:
        logger.error(f"An error occurred during visualization: {e}", exc_info=True)

def run_demo():
    try:
        logger.info("Starting AAOIFI Standards Multi-Agent System demonstration (New Orchestrator & Agents)")
        system = AAOIFIStandardsSystem()
        standard = load_sample_standard()
        logger.info(f"Loaded sample standard: {standard.name}")
        results = system.process_standard(standard)
        
        sample_feedback = """
        Feedback from Islamic Financial Institutions: 
        1. The technological integration suggestions for blockchain-based Murabahah tracking are innovative but may be too complex for immediate implementation.
        2. The clarification on agency arrangements is helpful, but requires more specific guidelines for documentation.
        
        Feedback from Shariah Scholars:
        1. The proposed modifications on risk transfer mechanisms need further elaboration to ensure full Shariah compliance.
        
        Feedback from Regulators:
        1. The proposed standardized documentation would facilitate regulatory oversight.
        """
        enhancement_data_for_feedback = results.get("enhancement")
        if enhancement_data_for_feedback is None:
             logger.error("Enhancement data is missing from process_standard results. Cannot proceed with feedback incorporation.")
             feedback_results = None
        else:
            feedback_results = system.incorporate_feedback(sample_feedback, enhancement_data_for_feedback)
        
        visualize_results(results)
        logger.info("Demonstration completed successfully (New Orchestrator & Agents)")
        return results, feedback_results
        
    except Exception as e:
        logger.error(f"Error in demonstration (New Orchestrator & Agents): {str(e)}", exc_info=True) 
        return None, None 


if __name__ == "__main__":
    logger.info("AAOIFI Standards Multi-Agent System - Main Execution Start")
    
    if not Config.OPENAI_API_KEY:
        logger.error("ERROR: OPENAI_API_KEY not set. Please set this environment variable or in the script.")
        exit(1)
    
    pdf_folder = Config.PDF_FOLDER
    db_dir = Config.DB_DIRECTORY 

    should_process_pdfs = False
    if not os.path.exists(db_dir) or (os.path.isdir(db_dir) and not os.listdir(db_dir)): 
        logger.warning(f"Vector DB directory '{db_dir}' appears to be missing or empty.")
        should_process_pdfs = True
    
    if should_process_pdfs:
        if os.path.exists(pdf_folder) and any(f.lower().endswith('.pdf') for f in os.listdir(pdf_folder)):
            try:
                user_choice = input(f"Vector DB at '{db_dir}' might be empty/missing. Process PDFs from '{pdf_folder}' to create/recreate it? (yes/no): ").strip().lower()
                if user_choice == 'yes':
                    logger.info("Attempting to process PDFs using safe recreate method...")
                    process_pdfs_safe() 
                    db_dir = Config.DB_DIRECTORY 
                    logger.info(f"PDF processing complete. DB is now at '{db_dir}'.")
                else:
                    logger.info("PDF processing skipped by user. Demo will proceed with current DB state.")
            except RuntimeError: 
                 logger.warning("input() is not available (e.g. some non-interactive environments). Skipping PDF processing prompt. Ensure DB is populated manually if needed.")
        else:
            logger.error(f"PDF folder '{pdf_folder}' is missing or empty. Cannot process PDFs. Demo might fail if DB is not populated.")

    logger.info("Running demonstration with New Orchestrator & Agents...")
    run_demo_results, run_demo_feedback_results = None, None 
    try:
        run_demo_results, run_demo_feedback_results = run_demo()
        if run_demo_results:
            logger.info(f"Demonstration results obtained for standard: {run_demo_results.get('standard_name')}")
        if run_demo_feedback_results:
            logger.info(f"Feedback analysis obtained for standard: {run_demo_feedback_results.get('standard_name')}")
    except Exception as e:
        logger.critical(f"Demonstration run failed critically: {e}", exc_info=True)

    logger.info(f"Main execution finished. Results (if any) saved to {Config.OUTPUT_DIR} directory.")